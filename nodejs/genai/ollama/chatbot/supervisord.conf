[supervisord]
nodaemon=true
logfile=/app/logs/supervisord.log
logfile_maxbytes=50MB
logfile_backups=10
loglevel=info
pidfile=/app/logs/supervisord.pid

[program:memcached]
command=memcached -m 64 -u memcache -p 11211
autostart=true
autorestart=true
stderr_logfile=/app/logs/memcached.err.log
stdout_logfile=/app/logs/memcached.out.log
user=nodejs

[program:ollama]
command=/usr/local/bin/ollama serve
autostart=true
autorestart=true
stdout_logfile=/app/logs/ollama.log
stderr_logfile=/app/logs/ollama_error.log
startsecs=10
user=nodejs

[program:ollama_model_pull]
; CHANGE: Add a loop to wait for Ollama server to be ready before pulling
command=bash -c " \
  until curl --fail http://localhost:11434/api/tags; do \
    echo 'Waiting for Ollama server to be ready to pull models...'; \
    sleep 5; \
  done; \
  /usr/local/bin/ollama pull mistral:7b"
autostart=true
autorestart=false ; Important: This program should only run once successfully
startsecs=0
depends_on=ollama ; Ensure this starts only after the 'ollama' server process is running
user=nodejs
stdout_logfile=/app/logs/ollama_model_pull.log
stderr_logfile=/app/logs/ollama_model_pull_error.log

[program:nodeapp]
command=bash -c " \
  echo 'Waiting for Ollama server to be ready and model to be pulled...'; \
  until /usr/local/bin/ollama show mistral:7b > /dev/null 2>&1; do \
    echo 'The model not found or Ollama not ready. Waiting...'; \
    sleep 10; \
  done; \
  echo 'Llama3 model found. Starting Node.js application.'; \
  exec /app/nodeexe"
autostart=true
autorestart=true
stderr_logfile=/app/logs/nodeapp.err.log
stdout_logfile=/app/logs/nodeapp.out.log
depends_on=ollama,memcached
user=nodejs
startsecs=250 ; Wait for up to 4 minutes for the Ollama server and model to be ready
